{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7227a308",
   "metadata": {},
   "source": [
    "### This notebook illustrates the steps in building a Naive Bayes model for classifying IMDB Movie Review sentiment (negative/positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a1578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#### LOAD DATASETS ####\n",
    "\n",
    "train_data_file = \"train.csv\"\n",
    "test_data_file = \"test.csv\"\n",
    "\n",
    "# Import train and test dataset into data frames and print out their lengths\n",
    "train_data_df = pd.read_csv(train_data_file)\n",
    "test_data_df = pd.read_csv(test_data_file)\n",
    "print (\"Train set: \",len(train_data_df))\n",
    "print (\"Test set: \",len(test_data_df))\n",
    "\n",
    "# print out top 5 rows of the train set\n",
    "display(train_data_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d013857c",
   "metadata": {},
   "source": [
    "### Count-based feature extraction using scikit-learn CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c72f66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# examine the features extracted using CountVectorizer for a small subset of instances\n",
    "text = train_data_df.iloc[0:3][\"review\"]\n",
    "print(text,\"\\n\")\n",
    "vectorizer = CountVectorizer(ngram_range = (1,1)) # adjust this ngram range to observe different n-grams\n",
    "\n",
    "# tokenize and build vocabulary\n",
    "vectorizer.fit(text)\n",
    "print(vectorizer.vocabulary_,\"\\n\")\n",
    "\n",
    "# create feature vector representation\n",
    "vector = vectorizer.transform(text)\n",
    "\n",
    "# summarize vector information, the integers associated with the n-grams are feature indices\n",
    "print(vector.shape,\"\\n\") \n",
    "\n",
    "# complete vectors\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02831cd",
   "metadata": {},
   "source": [
    "Interpret the feature vectors. What do they tell you about the individual examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff4a126",
   "metadata": {},
   "source": [
    "### Feature extraction using CountVectorizer for training and testing data on reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989db5e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use review for model building\n",
    "\n",
    "train_text = train_data_df[\"review\"]\n",
    "test_text = test_data_df[\"review\"]\n",
    "\n",
    "# set the n-gram range\n",
    "vectorizer = CountVectorizer(ngram_range = (1,1))\n",
    "\n",
    "# create training data representation\n",
    "train_data_cv = vectorizer.fit_transform(train_text.values.astype('U'))\n",
    "print(train_data_cv.shape,\"\\n\") \n",
    "\n",
    "# create test data representation\n",
    "test_data_cv = vectorizer.transform(test_text.values.astype('U'))\n",
    "print(test_data_cv.shape,\"\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b459142",
   "metadata": {},
   "source": [
    "Note the difference between how training and test data are vectorized (`fit_transform` vs. `transform`). \n",
    "Why is this needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fffd7d",
   "metadata": {},
   "source": [
    "## Building a Naive Bayes model using unigram features (bag-of-words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# define true labels from train set\n",
    "x_train = train_data_cv\n",
    "y_train = train_data_df[\"sentiment\"]\n",
    "x_test = test_data_cv\n",
    "y_test = test_data_df[\"sentiment\"]\n",
    "\n",
    "# build model on the training data\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# predict the labels for the test data\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848f474",
   "metadata": {},
   "source": [
    "### Saving and Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'NaiveBayesModelBOW.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# some time later...\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ed66d",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd010742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "print (\"Accuracy score: \", accuracy_score(y_test, predictions))\n",
    "print (\"Individual label performance: \")\n",
    "print (classification_report(y_test, predictions))\n",
    "print (confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430b3461",
   "metadata": {},
   "source": [
    "### Comparing the reviews where model predicted erroneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71702fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions\n",
    "labels = test_data_df[\"sentiment\"]\n",
    "inputs = test_data_df[\"review\"]\n",
    "\n",
    "for idx, prediction, label in zip(enumerate(inputs), predictions, labels):\n",
    "    if prediction != label:\n",
    "        print(\"Sample\", 'has been classified as', prediction, 'and should be', label, idx) \n",
    "        print (\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986994f6",
   "metadata": {},
   "source": [
    "### Feature extraction using TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221710b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# this time, we vectorize using TF-IDF\n",
    "text = train_data_df.iloc[0:3][\"review\"]\n",
    "print(text,\"\\n\")\n",
    "\n",
    "tf = TfidfVectorizer()\n",
    "tf.fit(text)\n",
    "\n",
    "print(tf.vocabulary_,\"\\n\")\n",
    "\n",
    "# encode document\n",
    "data = tf.transform(text)\n",
    "\n",
    "# summarize encoded vector\n",
    "print(data.shape,\"\\n\") \n",
    "print(data.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76844518",
   "metadata": {},
   "source": [
    "### Feature Extraction using TfidfVectorizer for training and testing data on Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7510390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tfidf = tf.fit_transform(train_text)\n",
    "print(train_data_tfidf.shape,\"\\n\") \n",
    "\n",
    "test_data_tfidf = tf.transform(test_text)\n",
    "print(test_data_tfidf.shape,\"\\n\") \n",
    "\n",
    "idf = tf.idf_\n",
    "\n",
    "# print out feature names (the words) and the IDF values\n",
    "print(dict(zip(tf.get_feature_names_out(), idf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9034a8",
   "metadata": {},
   "source": [
    "## Building and evaluate a Naive Bayes model using tf-idf representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1567c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define true labels from train set\n",
    "x_train = train_data_tfidf\n",
    "y_train = train_data_df[\"sentiment\"]\n",
    "x_test = test_data_tfidf\n",
    "y_test = test_data_df[\"sentiment\"]\n",
    "\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)\n",
    "\n",
    "print (\"Accuracy score: \", accuracy_score(y_test, predictions))\n",
    "print (\"Individual label performance: \")\n",
    "print (classification_report(y_test, predictions))\n",
    "print (confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e1bff",
   "metadata": {},
   "source": [
    "What can you say about the performance of Naive Bayes models created using count vectors and tf-idf vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a55a09",
   "metadata": {},
   "source": [
    "## Exploring EmoLex lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07033678",
   "metadata": {},
   "source": [
    "You can try **EmoLex**'s interactive playground here: https://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm under the heading **An Interactive Visualizer**. \n",
    "\n",
    "How can we incorporate the information in EmoLex in our classification models?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
