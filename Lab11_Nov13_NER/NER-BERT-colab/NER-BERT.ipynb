{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://www.analyticsvidhya.com/blog/2022/06/fine-tune-bert-model-for-named-entity-recognition-in-google-colab/"
      ],
      "metadata": {
        "id": "vE_YzIVRSulq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries"
      ],
      "metadata": {
        "id": "9SMcM7GZUGif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to install the necessary libraries to work with the HuggingFace transformer\n",
        "# datasets library to fetch data\n",
        "# tokenizers to preprocess the data\n",
        "# transformers to fine-tune the models\n",
        "# seqeval to compute model metrics\n",
        "\n",
        "!pip install datasets -q\n",
        "!pip install tokenizers -q\n",
        "!pip install transformers -q\n",
        "!pip install seqeval -q"
      ],
      "metadata": {
        "id": "IEHMf-5yQcuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load English dataset\n",
        "\n",
        "We will be using an English language NER dataset from the HuggingFace datasets module. It follows the BIO (Beginning, Inside, Outside) format for tagging sentence tokens for the Named Entity Recognition task.\n",
        "\n",
        "The dataset contains 3 sets of data, train, validation, and test. It consists of tokens, ner_tags, langs, and spans. The ner_tags have ids corresponding to BIO format, I-TYPE, which means the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of the second phrase will have the tag B-TYPE to show that it starts a new phrase. A word with the tag O is not part of a phrase.\n",
        "\n",
        "There is a total of 4 classes, Person(PER), Organization(ORG), Location(LOC), and others(O)."
      ],
      "metadata": {
        "id": "_uIWIHgaTt4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"wikiann\", \"en\")"
      ],
      "metadata": {
        "id": "5ftvO0-aTiJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.keys()"
      ],
      "metadata": {
        "id": "Yfiy27gQTwZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_names = dataset[\"train\"].features[\"ner_tags\"].feature.names\n",
        "label_names"
      ],
      "metadata": {
        "id": "OowzPZ87T1_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset['train'])"
      ],
      "metadata": {
        "id": "g55jcoCKT6P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.column_names"
      ],
      "metadata": {
        "id": "1b5huqbZag0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "JKZRaT8xf385"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train']"
      ],
      "metadata": {
        "id": "gsDnocmvXg8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][:2]"
      ],
      "metadata": {
        "id": "lGnp1jCceEDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "a8yIdgPmYclq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Bert expects input in `input_ids`, `token_type_ids` and `attention_mask` format\n",
        "- The label also requires adjustment due to subword tokenization used by BERT"
      ],
      "metadata": {
        "id": "MfKJrBniq9eS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "yaH8jnb-6aLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's see why we need to adjust the labels\n",
        "\n",
        "- We will process the tokens using tokenizer object"
      ],
      "metadata": {
        "id": "wXYojTrc1f_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"tokens\"], padding=\"max_length\", truncation=True, is_split_into_words=True)"
      ],
      "metadata": {
        "id": "in4FMztz20M4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets_ = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "PwWB89V320Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets_['train'][0]['input_ids'][:20]"
      ],
      "metadata": {
        "id": "N2_ltXdZ20G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets_['train'][0]['ner_tags'][:20]"
      ],
      "metadata": {
        "id": "7wqqPSvj6LvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenized_datasets_['train'][0]['input_ids']) == len(tokenized_datasets_['train'][0]['ner_tags'])"
      ],
      "metadata": {
        "id": "PqvSbwI112_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can see that len of `input_ids` is not matching with `ner_tags` that's why we require to adjust the labels according to the tokenized output"
      ],
      "metadata": {
        "id": "NeVi-DT_6jVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr/>"
      ],
      "metadata": {
        "id": "UeK0Bv5m1vCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We will use the argument truncation=True (to truncate texts that are bigger than the maximum size allowed by the model) as there is a sequence in data which has length>512"
      ],
      "metadata": {
        "id": "I6FGMjSS2kXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the values for input_ids, attention_mask, adjusted labels\n",
        "def tokenize_adjust_labels(all_samples_per_split):\n",
        "  tokenized_samples = tokenizer.batch_encode_plus(all_samples_per_split[\"tokens\"], is_split_into_words=True, truncation=True)\n",
        "\n",
        "  total_adjusted_labels = []\n",
        "\n",
        "  for k in range(0, len(tokenized_samples[\"input_ids\"])):\n",
        "    prev_wid = -1\n",
        "    word_ids_list = tokenized_samples.word_ids(batch_index=k)\n",
        "    existing_label_ids = all_samples_per_split[\"ner_tags\"][k]\n",
        "    i = -1\n",
        "    adjusted_label_ids = []\n",
        "\n",
        "    for word_idx in word_ids_list:\n",
        "      # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "      # ignored in the loss function.\n",
        "      if(word_idx is None):\n",
        "        adjusted_label_ids.append(-100)\n",
        "      elif(word_idx!=prev_wid):\n",
        "        i = i + 1\n",
        "        adjusted_label_ids.append(existing_label_ids[i])\n",
        "        prev_wid = word_idx\n",
        "      else:\n",
        "        label_name = label_names[existing_label_ids[i]]\n",
        "        adjusted_label_ids.append(existing_label_ids[i])\n",
        "\n",
        "    total_adjusted_labels.append(adjusted_label_ids)\n",
        "\n",
        "  #add adjusted labels to the tokenized samples\n",
        "  tokenized_samples[\"labels\"] = total_adjusted_labels\n",
        "  return tokenized_samples\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_adjust_labels, batched=True, remove_columns=['tokens', 'ner_tags', 'langs', 'spans'])"
      ],
      "metadata": {
        "id": "3fAoZmDdYcE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To understand word ids, consider following example"
      ],
      "metadata": {
        "id": "teMUwqXiW9IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = tokenizer(\"Fine tune NER in google colab!\")\n",
        "out"
      ],
      "metadata": {
        "id": "Psi3CWY9XGBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.word_ids(0)"
      ],
      "metadata": {
        "id": "MH2FE6fUWOsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can see 2 and 5 ids are repeated twice due to sub-word tokenization\n",
        "\n"
      ],
      "metadata": {
        "id": "limsUXrUXCQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We will now have all the required fields for training, 'input_ids', 'token_type_ids', 'attention_mask', 'labels'"
      ],
      "metadata": {
        "id": "GW7_lOfYqp8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset"
      ],
      "metadata": {
        "id": "tbjxPbzXqeDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset['train'][:2]"
      ],
      "metadata": {
        "id": "n2p9F2nGqmyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- As we can see, different sample have different length therefore we need to\n",
        "pad the tokens to have same length"
      ],
      "metadata": {
        "id": "g-aURLeBrsCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://huggingface.co/docs/transformers/main/main_classes/data_collator#transformers.DataCollatorForTokenClassification"
      ],
      "metadata": {
        "id": "hwd6wLo-stzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "5Vdz1YTAragY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator"
      ],
      "metadata": {
        "id": "oS98dpbUsHfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tuning"
      ],
      "metadata": {
        "id": "iUlrCMFctHGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForTokenClassification, AdamW"
      ],
      "metadata": {
        "id": "7sFRXB7IsI6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check if gpu is present\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "metadata": {
        "id": "cEvT2ePDt7CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We will use Distillbert-base-uncased model for fine tuning\n",
        "- We need to specify the number of labels present in the dataset"
      ],
      "metadata": {
        "id": "-BAW3u9v28gY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(label_names))\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "B3eooh_yt8nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a function to generate metrics\n",
        "- We will use `seqeval` metrics, commonly used for token classification"
      ],
      "metadata": {
        "id": "2xcmvgctxCxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install seqeval -q"
      ],
      "metadata": {
        "id": "vMk846nk87FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "\n",
        "    #select predicted index with maximum logit for each token\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "lI45-NU1xqV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = dataset[\"train\"][1]\n",
        "labels = [label_names[i] for i in example[f\"ner_tags\"]]\n",
        "metric.compute(predictions=[labels], references=[labels])"
      ],
      "metadata": {
        "id": "al2A2hiVBB28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Fine Tuning using Trainer API"
      ],
      "metadata": {
        "id": "FjFwNtQQ33FA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U accelerate\n",
        "! pip install -U transformers"
      ],
      "metadata": {
        "id": "28E8ZpWVRr1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "batch_size = 16\n",
        "logging_steps = len(tokenized_dataset['train']) // batch_size\n",
        "epochs = 2\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/bert-fine-tune-ner/results\",\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    disable_tqdm=False,\n",
        "    logging_steps=logging_steps)"
      ],
      "metadata": {
        "id": "u7OHFke0wWIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ],
      "metadata": {
        "id": "S_ywBZhpwWFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train_dataset[0]"
      ],
      "metadata": {
        "id": "IqWyTbZ80r8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.eval_dataset[0]"
      ],
      "metadata": {
        "id": "NbUAdUIHADaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fine tune using train method\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "81mGl05TECUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "QaP_mXvSgu_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the precision/recall/f1 computed for each category for test set, we can apply the same function as before on the result of the `predict` method:"
      ],
      "metadata": {
        "id": "aJWzwcECtLh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, labels, _ = trainer.predict(tokenized_dataset[\"test\"])\n",
        "predictions = np.argmax(predictions, axis=2)\n",
        "# Remove ignored index (special tokens)\n",
        "true_predictions = [\n",
        "    [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "true_labels = [\n",
        "    [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "]\n",
        "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "results"
      ],
      "metadata": {
        "id": "r0xDmf9ssd-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observations\n",
        "\n",
        "- f1 score for LOC and PER is >85% and ORG has <75%\n",
        "- Overall f1 score is ~83%\n",
        "- We can improve the accuracy by training the model for more number of epochs (currently only 2 epochs)"
      ],
      "metadata": {
        "id": "OPYxuTQwxNCD"
      }
    }
  ]
}