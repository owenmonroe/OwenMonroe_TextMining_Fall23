{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is Owen Monroe's Homework Assignment # 3 for Text Mining IS 567\n",
    "October 8, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train and evaluate a unigram-based baseline classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829\n",
      "458\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/21/2023 16:42</td>\n",
       "      <td>Much more accessible for blind users than the ...</td>\n",
       "      <td>Up to this point I?€?ve mostly been using Chat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/11/2023 12:24</td>\n",
       "      <td>Much anticipated, wasn?€?t let down.</td>\n",
       "      <td>I?€?ve been a user since it?€?s initial roll o...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/19/2023 10:16</td>\n",
       "      <td>Almost 5 stars, but?€? no search function</td>\n",
       "      <td>This app would almost be perfect if it wasn?€?...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/27/2023 21:57</td>\n",
       "      <td>4.5 stars, here?€?s why</td>\n",
       "      <td>I recently downloaded the app and overall, it'...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/9/2023 7:49</td>\n",
       "      <td>Good, but Siri support would take it to the ne...</td>\n",
       "      <td>I appreciate the devs implementing Siri suppor...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>6/4/2023 10:50</td>\n",
       "      <td>pad os???</td>\n",
       "      <td>Please make a iPad version of this</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>5/19/2023 1:23</td>\n",
       "      <td>Goated app</td>\n",
       "      <td>Best app</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>6/21/2023 20:02</td>\n",
       "      <td>Co</td>\n",
       "      <td>Why it?€?s not available in Ethiopia</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>6/7/2023 10:25</td>\n",
       "      <td>Crazy world views</td>\n",
       "      <td>It agrees with letting children be forced into...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>5/18/2023 23:07</td>\n",
       "      <td>Good app</td>\n",
       "      <td>It?€?s good</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1829 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title  \\\n",
       "0     5/21/2023 16:42  Much more accessible for blind users than the ...   \n",
       "1     7/11/2023 12:24               Much anticipated, wasn?€?t let down.   \n",
       "2     5/19/2023 10:16          Almost 5 stars, but?€? no search function   \n",
       "3     5/27/2023 21:57                            4.5 stars, here?€?s why   \n",
       "4       6/9/2023 7:49  Good, but Siri support would take it to the ne...   \n",
       "...               ...                                                ...   \n",
       "1829   6/4/2023 10:50                                          pad os???   \n",
       "1830   5/19/2023 1:23                                         Goated app   \n",
       "1831  6/21/2023 20:02                                                 Co   \n",
       "1832   6/7/2023 10:25                                  Crazy world views   \n",
       "1833  5/18/2023 23:07                                           Good app   \n",
       "\n",
       "                                                 review  rating  \n",
       "0     Up to this point I?€?ve mostly been using Chat...       4  \n",
       "1     I?€?ve been a user since it?€?s initial roll o...       4  \n",
       "2     This app would almost be perfect if it wasn?€?...       4  \n",
       "3     I recently downloaded the app and overall, it'...       4  \n",
       "4     I appreciate the devs implementing Siri suppor...       4  \n",
       "...                                                 ...     ...  \n",
       "1829                 Please make a iPad version of this       1  \n",
       "1830                                           Best app       5  \n",
       "1831               Why it?€?s not available in Ethiopia       1  \n",
       "1832  It agrees with letting children be forced into...       1  \n",
       "1833                                        It?€?s good       5  \n",
       "\n",
       "[1829 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading Data and Removing Empties\n",
    "\n",
    "train_df = pd.read_csv('chatgpt_train.csv')\n",
    "test_df = pd.read_csv('chatgpt_test.csv')\n",
    "\n",
    "full_train_df = train_df.dropna()\n",
    "full_test_df = test_df.dropna()\n",
    "\n",
    "print(len(full_train_df['review'].to_list()))\n",
    "print(len(full_test_df['review'].to_list()))\n",
    "\n",
    "full_train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Convert Ratings to Three-Way Ratings\n",
    "\n",
    "def change_five_to_three(rating):\n",
    "    if rating in [1, 2]:\n",
    "        return 'negative'\n",
    "    elif rating == 3:\n",
    "        return 'neutral'\n",
    "    elif rating in [4, 5]:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8c/38d5fhqx2_jf385d_b3cq3j00000gn/T/ipykernel_55994/896341391.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_train_df['three rating'] = three_rate_train_list\n"
     ]
    }
   ],
   "source": [
    "# New Rating List for Train and Test Data\n",
    "\n",
    "three_rate_train_list = full_train_df['rating'].apply(change_five_to_three).to_list()\n",
    "three_rate_test_list = full_test_df['rating'].apply(change_five_to_three).to_list()\n",
    "\n",
    "\n",
    "full_train_df['three rating'] = three_rate_train_list\n",
    "full_test_df['three rating'] = three_rate_test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>three rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/21/2023 16:42</td>\n",
       "      <td>Much more accessible for blind users than the ...</td>\n",
       "      <td>Up to this point I?€?ve mostly been using Chat...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/11/2023 12:24</td>\n",
       "      <td>Much anticipated, wasn?€?t let down.</td>\n",
       "      <td>I?€?ve been a user since it?€?s initial roll o...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/19/2023 10:16</td>\n",
       "      <td>Almost 5 stars, but?€? no search function</td>\n",
       "      <td>This app would almost be perfect if it wasn?€?...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/27/2023 21:57</td>\n",
       "      <td>4.5 stars, here?€?s why</td>\n",
       "      <td>I recently downloaded the app and overall, it'...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/9/2023 7:49</td>\n",
       "      <td>Good, but Siri support would take it to the ne...</td>\n",
       "      <td>I appreciate the devs implementing Siri suppor...</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>6/4/2023 10:50</td>\n",
       "      <td>pad os???</td>\n",
       "      <td>Please make a iPad version of this</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>5/19/2023 1:23</td>\n",
       "      <td>Goated app</td>\n",
       "      <td>Best app</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>6/21/2023 20:02</td>\n",
       "      <td>Co</td>\n",
       "      <td>Why it?€?s not available in Ethiopia</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>6/7/2023 10:25</td>\n",
       "      <td>Crazy world views</td>\n",
       "      <td>It agrees with letting children be forced into...</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>5/18/2023 23:07</td>\n",
       "      <td>Good app</td>\n",
       "      <td>It?€?s good</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1829 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title  \\\n",
       "0     5/21/2023 16:42  Much more accessible for blind users than the ...   \n",
       "1     7/11/2023 12:24               Much anticipated, wasn?€?t let down.   \n",
       "2     5/19/2023 10:16          Almost 5 stars, but?€? no search function   \n",
       "3     5/27/2023 21:57                            4.5 stars, here?€?s why   \n",
       "4       6/9/2023 7:49  Good, but Siri support would take it to the ne...   \n",
       "...               ...                                                ...   \n",
       "1829   6/4/2023 10:50                                          pad os???   \n",
       "1830   5/19/2023 1:23                                         Goated app   \n",
       "1831  6/21/2023 20:02                                                 Co   \n",
       "1832   6/7/2023 10:25                                  Crazy world views   \n",
       "1833  5/18/2023 23:07                                           Good app   \n",
       "\n",
       "                                                 review  rating three rating  \n",
       "0     Up to this point I?€?ve mostly been using Chat...       4     positive  \n",
       "1     I?€?ve been a user since it?€?s initial roll o...       4     positive  \n",
       "2     This app would almost be perfect if it wasn?€?...       4     positive  \n",
       "3     I recently downloaded the app and overall, it'...       4     positive  \n",
       "4     I appreciate the devs implementing Siri suppor...       4     positive  \n",
       "...                                                 ...     ...          ...  \n",
       "1829                 Please make a iPad version of this       1     negative  \n",
       "1830                                           Best app       5     positive  \n",
       "1831               Why it?€?s not available in Ethiopia       1     negative  \n",
       "1832  It agrees with letting children be forced into...       1     negative  \n",
       "1833                                        It?€?s good       5     positive  \n",
       "\n",
       "[1829 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>three rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/19/2023 6:09</td>\n",
       "      <td>error unsupported country</td>\n",
       "      <td>cant login</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/19/2023 9:39</td>\n",
       "      <td>Hype junk</td>\n",
       "      <td>More harm than help.</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/19/2023 4:12</td>\n",
       "      <td>your gpt 4 is fake</td>\n",
       "      <td>Fix it</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/20/2023 3:01</td>\n",
       "      <td>Please impose IPadOS</td>\n",
       "      <td>We need IPadOS!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/19/2023 20:49</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>Great</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>5/19/2023 0:17</td>\n",
       "      <td>Andrew Justino Wilson 5/19/23</td>\n",
       "      <td>This has to be a beginning to something crazy ...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>5/18/2023 19:13</td>\n",
       "      <td>Superb AI</td>\n",
       "      <td>I?€?ve been using chat and have been a proud p...</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>5/18/2023 18:27</td>\n",
       "      <td>Fantastic App with Room for Enhancements</td>\n",
       "      <td>The ChatGPT iOS app is an outstanding product....</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>5/18/2023 17:17</td>\n",
       "      <td>Awesome technology, deplorable tactics</td>\n",
       "      <td>Sam Altman?€?s blatant attempt at regulatory c...</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>7/25/2023 0:50</td>\n",
       "      <td>I like how there r no limits thanks &lt;33</td>\n",
       "      <td>.</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>458 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date                                     title  \\\n",
       "0     5/19/2023 6:09                 error unsupported country   \n",
       "1     5/19/2023 9:39                                 Hype junk   \n",
       "2     5/19/2023 4:12                        your gpt 4 is fake   \n",
       "3     5/20/2023 3:01                      Please impose IPadOS   \n",
       "4    5/19/2023 20:49                                   Amazing   \n",
       "..               ...                                       ...   \n",
       "453   5/19/2023 0:17             Andrew Justino Wilson 5/19/23   \n",
       "454  5/18/2023 19:13                                 Superb AI   \n",
       "455  5/18/2023 18:27  Fantastic App with Room for Enhancements   \n",
       "456  5/18/2023 17:17    Awesome technology, deplorable tactics   \n",
       "457   7/25/2023 0:50   I like how there r no limits thanks <33   \n",
       "\n",
       "                                                review  rating three rating  \n",
       "0                                           cant login       2     negative  \n",
       "1                                 More harm than help.       1     negative  \n",
       "2                                               Fix it       1     negative  \n",
       "3                                    We need IPadOS!!!       5     positive  \n",
       "4                                                Great       5     positive  \n",
       "..                                                 ...     ...          ...  \n",
       "453  This has to be a beginning to something crazy ...       5     positive  \n",
       "454  I?€?ve been using chat and have been a proud p...       5     positive  \n",
       "455  The ChatGPT iOS app is an outstanding product....       5     positive  \n",
       "456  Sam Altman?€?s blatant attempt at regulatory c...       2     negative  \n",
       "457                                                  .       5     positive  \n",
       "\n",
       "[458 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829, 5551) \n",
      "\n",
      "(458, 5551) \n",
      "\n",
      "  (0, 5224)\t1\n",
      "  (0, 4985)\t9\n",
      "  (0, 4932)\t5\n",
      "  (0, 3613)\t1\n",
      "  (0, 5282)\t1\n",
      "  (0, 3134)\t1\n",
      "  (0, 493)\t2\n",
      "  (0, 5253)\t2\n",
      "  (0, 776)\t2\n",
      "  (0, 3331)\t3\n",
      "  (0, 3165)\t2\n",
      "  (0, 5454)\t1\n",
      "  (0, 1302)\t3\n",
      "  (0, 2139)\t1\n",
      "  (0, 806)\t1\n",
      "  (0, 5421)\t1\n",
      "  (0, 2666)\t6\n",
      "  (0, 1426)\t1\n",
      "  (0, 4267)\t3\n",
      "  (0, 3883)\t2\n",
      "  (0, 3184)\t1\n",
      "  (0, 2660)\t3\n",
      "  (0, 3692)\t2\n",
      "  (0, 1352)\t1\n",
      "  (0, 4906)\t16\n",
      "  :\t:\n",
      "  (1824, 2949)\t1\n",
      "  (1824, 3593)\t1\n",
      "  (1824, 2644)\t1\n",
      "  (1824, 5301)\t1\n",
      "  (1825, 291)\t1\n",
      "  (1825, 527)\t1\n",
      "  (1826, 2666)\t1\n",
      "  (1826, 2456)\t1\n",
      "  (1826, 413)\t1\n",
      "  (1826, 3247)\t1\n",
      "  (1826, 5433)\t1\n",
      "  (1826, 1695)\t1\n",
      "  (1827, 2666)\t1\n",
      "  (1827, 474)\t1\n",
      "  (1827, 5464)\t1\n",
      "  (1827, 2619)\t1\n",
      "  (1827, 3372)\t1\n",
      "  (1827, 1976)\t1\n",
      "  (1827, 2807)\t1\n",
      "  (1827, 794)\t1\n",
      "  (1827, 195)\t1\n",
      "  (1827, 3699)\t1\n",
      "  (1827, 2328)\t1\n",
      "  (1828, 2666)\t1\n",
      "  (1828, 2135)\t1\n"
     ]
    }
   ],
   "source": [
    "train_rev_text = full_train_df[\"review\"]\n",
    "test_rev_text = full_test_df[\"review\"]\n",
    "\n",
    "# Setting n-gram range to uni-grams\n",
    "vectorizer = CountVectorizer(ngram_range = (1, 1))\n",
    "\n",
    "# Creating training data representation\n",
    "train_rev_uni_cv = vectorizer.fit_transform(train_rev_text.values.astype('U'))\n",
    "print(train_rev_uni_cv.shape,\"\\n\") \n",
    "\n",
    "# Creating test data representation\n",
    "test_rev_uni_cv = vectorizer.transform(test_rev_text.values.astype('U'))\n",
    "print(test_rev_uni_cv.shape,\"\\n\") \n",
    "\n",
    "print(train_rev_uni_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'negative', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define true labels from train set\n",
    "\n",
    "x_train_cv = train_rev_uni_cv\n",
    "y_train_rev_series = full_train_df[\"three rating\"]\n",
    "x_test_cv = test_rev_uni_cv\n",
    "y_test_rev_series = full_test_df[\"three rating\"]\n",
    "\n",
    "# Build model on the training data\n",
    "\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train_cv, y_train_rev_series)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "\n",
    "predictions = mnb_model.predict(x_test_cv)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "true_label_list = y_test_rev_series.to_list()\n",
    "predict_label_list = list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Reports - Unigrams NB Baseline\n",
      "\n",
      "Accuracy Score: 0.7358078602620087\n",
      "\n",
      "Precision Scores\n",
      "macro precision score for unigrams = 0.5420844714259355\n",
      "micro precision score for unigrams = 0.7358078602620087\n",
      "weighted precision score for unigrams = 0.7128098567692405\n",
      "\n",
      "Recall Scores\n",
      "macro recall score for unigrams = 0.5007752841737103\n",
      "micro recall score for unigrams = 0.7358078602620087\n",
      "weighted recall score for unigrams = 0.7358078602620087\n",
      "\n",
      "F1 Scores\n",
      "macro F1 score for unigrams = 0.5116057233704292\n",
      "micro F1 score for unigrams = 0.7358078602620087\n",
      "weighted F1 score for unigrams = 0.7176894078769239\n"
     ]
    }
   ],
   "source": [
    "# Getting Evaluation Metrics for NB Unigrams \n",
    "\n",
    "true_label_list = y_test_rev_series.to_list()\n",
    "predict_label_list = list(predictions)\n",
    "\n",
    "acc_score = accuracy_score(true_label_list, predict_label_list)\n",
    "\n",
    "prec_score_macro = precision_score(true_label_list, predict_label_list, average='macro')\n",
    "prec_score_micro = precision_score(true_label_list, predict_label_list, average='micro')\n",
    "prec_score_weighted = precision_score(true_label_list, predict_label_list, average='weighted')\n",
    "\n",
    "rec_score_macro = recall_score(true_label_list, predict_label_list, average='macro')\n",
    "rec_score_micro = recall_score(true_label_list, predict_label_list, average='micro')\n",
    "rec_score_weighted = recall_score(true_label_list, predict_label_list, average='weighted')\n",
    "\n",
    "f1_score_macro = f1_score(true_label_list, predict_label_list, average='macro')\n",
    "f1_score_micro = f1_score(true_label_list, predict_label_list, average='micro')\n",
    "f1_score_weighted = f1_score(true_label_list, predict_label_list, average='weighted')\n",
    "\n",
    "\n",
    "print('Evaluation Reports - Unigrams NB Baseline')\n",
    "print()\n",
    "print(f'Accuracy Score: {acc_score}')\n",
    "print()\n",
    "print('Precision Scores')\n",
    "print(f'macro precision score for unigrams = {prec_score_macro}')\n",
    "print(f'micro precision score for unigrams = {prec_score_micro}')\n",
    "print(f'weighted precision score for unigrams = {prec_score_weighted}')\n",
    "print()\n",
    "print('Recall Scores')\n",
    "print(f'macro recall score for unigrams = {rec_score_macro}')\n",
    "print(f'micro recall score for unigrams = {rec_score_micro}')\n",
    "print(f'weighted recall score for unigrams = {rec_score_weighted}')\n",
    "print()\n",
    "print('F1 Scores')\n",
    "print(f'macro F1 score for unigrams = {f1_score_macro}')\n",
    "print(f'micro F1 score for unigrams = {f1_score_micro}')\n",
    "print(f'weighted F1 score for unigrams = {f1_score_weighted}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove Features with Low Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space before filtering:  (1829, 5551)\n",
      "Train feature space after filtering:  (1829, 3054)\n",
      "Test feature space before filtering:  (458, 5551)\n",
      "Test feature space after filtering:  (458, 3054)\n",
      "  (0, 389)\t1\n",
      "  (0, 1619)\t1\n",
      "  (1, 1243)\t1\n",
      "  (1, 1267)\t1\n",
      "  (1, 1753)\t1\n",
      "  (1, 2682)\t1\n",
      "  (2, 1067)\t1\n",
      "  (2, 1478)\t1\n",
      "  (3, 1467)\t1\n",
      "  (3, 1789)\t1\n",
      "  (3, 2960)\t1\n",
      "  (4, 1204)\t1\n",
      "  (5, 164)\t1\n",
      "  (5, 1187)\t1\n",
      "  (5, 1473)\t1\n",
      "  (5, 2168)\t1\n",
      "  (5, 2706)\t1\n",
      "  (6, 1063)\t1\n",
      "  (7, 164)\t1\n",
      "  (7, 1853)\t1\n",
      "  (8, 1195)\t2\n",
      "  (8, 1473)\t1\n",
      "  (8, 1890)\t1\n",
      "  (8, 2706)\t1\n",
      "  (10, 443)\t1\n",
      "  :\t:\n",
      "  (455, 2912)\t1\n",
      "  (455, 2991)\t1\n",
      "  (455, 3003)\t2\n",
      "  (455, 3004)\t1\n",
      "  (455, 3028)\t5\n",
      "  (456, 62)\t1\n",
      "  (456, 107)\t1\n",
      "  (456, 128)\t1\n",
      "  (456, 214)\t1\n",
      "  (456, 222)\t1\n",
      "  (456, 223)\t1\n",
      "  (456, 281)\t1\n",
      "  (456, 317)\t1\n",
      "  (456, 443)\t1\n",
      "  (456, 772)\t1\n",
      "  (456, 1091)\t1\n",
      "  (456, 1139)\t1\n",
      "  (456, 1846)\t1\n",
      "  (456, 1872)\t2\n",
      "  (456, 2330)\t1\n",
      "  (456, 2483)\t1\n",
      "  (456, 2687)\t1\n",
      "  (456, 2738)\t1\n",
      "  (456, 2972)\t1\n",
      "  (456, 3003)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Removing Features with threshold below 0.001\n",
    "\n",
    "selector = VarianceThreshold(threshold = 0.001)\n",
    "\n",
    "X_train_features_filtered_var_thr_1 = selector.fit(train_rev_uni_cv).transform(train_rev_uni_cv)\n",
    "print (\"Train feature space before filtering: \", train_rev_uni_cv.shape)\n",
    "print (\"Train feature space after filtering: \", X_train_features_filtered_var_thr_1.shape)\n",
    "\n",
    "X_test_features_filtered_var_thr_1 = selector.transform(test_rev_uni_cv)\n",
    "print (\"Test feature space before filtering: \", test_rev_uni_cv.shape)\n",
    "print (\"Test feature space after filtering: \", X_test_features_filtered_var_thr_1.shape)\n",
    "\n",
    "print(X_test_features_filtered_var_thr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'neutral', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'neutral', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training an NB Model for the Feature Space with Low Variance Features Removed threshold below 0.001\n",
    "\n",
    "# Define true labels from train set\n",
    "\n",
    "x_train_cv_low1 = X_train_features_filtered_var_thr_1\n",
    "y_train_rev_series = full_train_df[\"three rating\"]\n",
    "x_test_cv_low1 = X_test_features_filtered_var_thr_1\n",
    "y_test_rev_series = full_test_df[\"three rating\"]\n",
    "\n",
    "# Build model on the training data\n",
    "\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train_cv_low1, y_train_rev_series)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "\n",
    "predictions_low1 = mnb_model.predict(x_test_cv_low1)\n",
    "predictions_low1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Reports - NB with Low Variance Features Removed, Threshold of 0.001 \n",
      "\n",
      "Accuracy Score: 0.7270742358078602\n",
      "\n",
      "Precision Scores\n",
      "macro precision score for unigrams = 0.5286054212610907\n",
      "micro precision score for unigrams = 0.7270742358078602\n",
      "weighted precision score for unigrams = 0.7060217680304899\n",
      "\n",
      "Recall Scores\n",
      "macro recall score for unigrams = 0.4974315878104861\n",
      "micro recall score for unigrams = 0.7270742358078602\n",
      "weighted recall score for unigrams = 0.7270742358078602\n",
      "\n",
      "F1 Scores\n",
      "macro F1 score for unigrams = 0.5065362940263409\n",
      "micro F1 score for unigrams = 0.7270742358078602\n",
      "weighted F1 score for unigrams = 0.7117444835328599\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics for NB with Low Variance Features Removed, Threshold of 0.001\n",
    "\n",
    "true_label_list = y_test_rev_series.to_list()\n",
    "predict_label_list_low1 = list(predictions_low1)\n",
    "\n",
    "acc_score = accuracy_score(true_label_list, predict_label_list_low1)\n",
    "\n",
    "prec_score_macro = precision_score(true_label_list, predict_label_list_low1, average='macro')\n",
    "prec_score_micro = precision_score(true_label_list, predict_label_list_low1, average='micro')\n",
    "prec_score_weighted = precision_score(true_label_list, predict_label_list_low1, average='weighted')\n",
    "\n",
    "rec_score_macro = recall_score(true_label_list, predict_label_list_low1, average='macro')\n",
    "rec_score_micro = recall_score(true_label_list, predict_label_list_low1, average='micro')\n",
    "rec_score_weighted = recall_score(true_label_list, predict_label_list_low1, average='weighted')\n",
    "\n",
    "f1_score_macro = f1_score(true_label_list, predict_label_list_low1, average='macro')\n",
    "f1_score_micro = f1_score(true_label_list, predict_label_list_low1, average='micro')\n",
    "f1_score_weighted = f1_score(true_label_list, predict_label_list_low1, average='weighted')\n",
    "\n",
    "\n",
    "print('Evaluation Reports - NB with Low Variance Features Removed, Threshold of 0.001 ')\n",
    "print()\n",
    "print(f'Accuracy Score: {acc_score}')\n",
    "print()\n",
    "print('Precision Scores')\n",
    "print(f'macro precision score = {prec_score_macro}')\n",
    "print(f'micro precision score = {prec_score_micro}')\n",
    "print(f'weighted precision score = {prec_score_weighted}')\n",
    "print()\n",
    "print('Recall Scores')\n",
    "print(f'macro recall score = {rec_score_macro}')\n",
    "print(f'micro recall score = {rec_score_micro}')\n",
    "print(f'weighted recall score = {rec_score_weighted}')\n",
    "print()\n",
    "print('F1 Scores')\n",
    "print(f'macro F1 score = {f1_score_macro}')\n",
    "print(f'micro F1 score = {f1_score_micro}')\n",
    "print(f'weighted F1 score = {f1_score_weighted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space before filtering:  (1829, 5551)\n",
      "Train feature space after filtering:  (1829, 980)\n",
      "Test feature space before filtering:  (458, 5551)\n",
      "Test feature space after filtering:  (458, 980)\n",
      "  (0, 507)\t1\n",
      "  (1, 387)\t1\n",
      "  (1, 546)\t1\n",
      "  (1, 831)\t1\n",
      "  (2, 320)\t1\n",
      "  (2, 459)\t1\n",
      "  (3, 558)\t1\n",
      "  (3, 932)\t1\n",
      "  (4, 367)\t1\n",
      "  (5, 65)\t1\n",
      "  (5, 361)\t1\n",
      "  (5, 455)\t1\n",
      "  (5, 680)\t1\n",
      "  (5, 846)\t1\n",
      "  (6, 318)\t1\n",
      "  (7, 65)\t1\n",
      "  (7, 577)\t1\n",
      "  (8, 364)\t2\n",
      "  (8, 455)\t1\n",
      "  (8, 589)\t1\n",
      "  (8, 846)\t1\n",
      "  (10, 142)\t1\n",
      "  (10, 572)\t1\n",
      "  (10, 579)\t1\n",
      "  (10, 914)\t1\n",
      "  :\t:\n",
      "  (455, 870)\t1\n",
      "  (455, 891)\t1\n",
      "  (455, 900)\t3\n",
      "  (455, 901)\t4\n",
      "  (455, 908)\t1\n",
      "  (455, 913)\t1\n",
      "  (455, 954)\t2\n",
      "  (455, 955)\t1\n",
      "  (455, 966)\t5\n",
      "  (456, 25)\t1\n",
      "  (456, 40)\t1\n",
      "  (456, 83)\t1\n",
      "  (456, 84)\t1\n",
      "  (456, 104)\t1\n",
      "  (456, 142)\t1\n",
      "  (456, 235)\t1\n",
      "  (456, 325)\t1\n",
      "  (456, 342)\t1\n",
      "  (456, 572)\t1\n",
      "  (456, 584)\t2\n",
      "  (456, 775)\t1\n",
      "  (456, 835)\t1\n",
      "  (456, 856)\t1\n",
      "  (456, 936)\t1\n",
      "  (456, 954)\t1\n"
     ]
    }
   ],
   "source": [
    "selector_5 = VarianceThreshold(threshold = 0.005)\n",
    "\n",
    "X_train_features_filtered_var_thr_5 = selector_5.fit(train_rev_uni_cv).transform(train_rev_uni_cv)\n",
    "print (\"Train feature space before filtering: \", train_rev_uni_cv.shape)\n",
    "print (\"Train feature space after filtering: \", X_train_features_filtered_var_thr_5.shape)\n",
    "\n",
    "X_test_features_filtered_var_thr_5 = selector_5.transform(test_rev_uni_cv)\n",
    "print (\"Test feature space before filtering: \", test_rev_uni_cv.shape)\n",
    "print (\"Test feature space after filtering: \", X_test_features_filtered_var_thr_5.shape)\n",
    "\n",
    "print(X_test_features_filtered_var_thr_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'neutral', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'neutral', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'neutral', 'neutral',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'negative', 'positive', 'negative',\n",
       "       'negative', 'neutral', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training an NB Model for the Feature Space with Low Variance Features Removed threshold below 0.005\n",
    "\n",
    "# Define true labels from train set\n",
    "\n",
    "x_train_cv_low5 = X_train_features_filtered_var_thr_5\n",
    "y_train_rev_series = full_train_df[\"three rating\"]\n",
    "x_test_cv_low5 = X_test_features_filtered_var_thr_5\n",
    "y_test_rev_series = full_test_df[\"three rating\"]\n",
    "\n",
    "# Build model on the training data\n",
    "\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train_cv_low5, y_train_rev_series)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "\n",
    "predictions_low5 = mnb_model.predict(x_test_cv_low5)\n",
    "predictions_low5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Reports - NB with Low Variance Features Removed, Threshold of 0.005 \n",
      "\n",
      "Accuracy Score: 0.7358078602620087\n",
      "\n",
      "Precision Scores\n",
      "macro precision score = 0.5362426035502958\n",
      "micro precision score = 0.7358078602620087\n",
      "weighted precision score = 0.7181904214361385\n",
      "\n",
      "Recall Scores\n",
      "macro recall score = 0.4995527704912724\n",
      "micro recall score = 0.7358078602620087\n",
      "weighted recall score = 0.7358078602620087\n",
      "\n",
      "F1 Scores\n",
      "macro F1 score = 0.5100713456114153\n",
      "micro F1 score = 0.7358078602620087\n",
      "weighted F1 score = 0.7195576238803115\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics for NB with Low Variance Features Removed, Threshold of 0.005\n",
    "\n",
    "true_label_list = y_test_rev_series.to_list()\n",
    "predict_label_list_low5 = list(predictions_low5)\n",
    "\n",
    "acc_score = accuracy_score(true_label_list, predict_label_list_low5)\n",
    "\n",
    "prec_score_macro = precision_score(true_label_list, predict_label_list_low5, average='macro')\n",
    "prec_score_micro = precision_score(true_label_list, predict_label_list_low5, average='micro')\n",
    "prec_score_weighted = precision_score(true_label_list, predict_label_list_low5, average='weighted')\n",
    "\n",
    "rec_score_macro = recall_score(true_label_list, predict_label_list_low5, average='macro')\n",
    "rec_score_micro = recall_score(true_label_list, predict_label_list_low5, average='micro')\n",
    "rec_score_weighted = recall_score(true_label_list, predict_label_list_low5, average='weighted')\n",
    "\n",
    "f1_score_macro = f1_score(true_label_list, predict_label_list_low5, average='macro')\n",
    "f1_score_micro = f1_score(true_label_list, predict_label_list_low5, average='micro')\n",
    "f1_score_weighted = f1_score(true_label_list, predict_label_list_low5, average='weighted')\n",
    "\n",
    "\n",
    "print('Evaluation Reports - NB with Low Variance Features Removed, Threshold of 0.005 ')\n",
    "print()\n",
    "print(f'Accuracy Score: {acc_score}')\n",
    "print()\n",
    "print('Precision Scores')\n",
    "print(f'macro precision score = {prec_score_macro}')\n",
    "print(f'micro precision score = {prec_score_micro}')\n",
    "print(f'weighted precision score = {prec_score_weighted}')\n",
    "print()\n",
    "print('Recall Scores')\n",
    "print(f'macro recall score = {rec_score_macro}')\n",
    "print(f'micro recall score = {rec_score_micro}')\n",
    "print(f'weighted recall score = {rec_score_weighted}')\n",
    "print()\n",
    "print('F1 Scores')\n",
    "print(f'macro F1 score = {f1_score_macro}')\n",
    "print(f'micro F1 score = {f1_score_micro}')\n",
    "print(f'weighted F1 score = {f1_score_weighted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Select top k-best features using information gain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space before filtering:  (1829, 5551)\n",
      "Train feature space after filtering:  (1829, 1000)\n",
      "Test feature space before filtering:  (458, 5551)\n",
      "Test feature space after filtering:  (458, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Selecting K-best features with k = 1000\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "selector = SelectKBest(chi2, k=1000)\n",
    "X_train_features_filtered_kbest1 = selector.fit_transform(x_train_cv, y_train_rev_series)\n",
    "print (\"Train feature space before filtering: \", x_train_cv.shape)\n",
    "print (\"Train feature space after filtering: \", X_train_features_filtered_kbest1.shape)\n",
    "\n",
    "X_test_features_filtered_kbest1 = selector.transform(x_test_cv)\n",
    "print (\"Test feature space before filtering: \", x_test_cv.shape)\n",
    "print (\"Test feature space after filtering: \", X_test_features_filtered_kbest1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'neutral', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'negative', 'neutral', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive', 'neutral',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'neutral', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training an NB Model for the Feature Space with K-best features k = 1000\n",
    "\n",
    "# Define true labels from train set\n",
    "\n",
    "x_train_cv_k1 = X_train_features_filtered_kbest1\n",
    "y_train_rev_series = full_train_df[\"three rating\"]\n",
    "x_test_cv_k1 = X_test_features_filtered_kbest1\n",
    "y_test_rev_series = full_test_df[\"three rating\"]\n",
    "\n",
    "# Build model on the training data\n",
    "\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train_cv_k1, y_train_rev_series)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "\n",
    "predictions_k1 = mnb_model.predict(x_test_cv_k1)\n",
    "predictions_k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Reports - NB wfor the Feature Space with K-best features k = 1000\n",
      "\n",
      "Accuracy Score: 0.7489082969432315\n",
      "\n",
      "Precision Scores\n",
      "macro precision score = 0.5667439727843752\n",
      "micro precision score = 0.7489082969432315\n",
      "weighted precision score = 0.7331256698532228\n",
      "\n",
      "Recall Scores\n",
      "macro recall score = 0.5185938663816834\n",
      "micro recall score = 0.7489082969432315\n",
      "weighted recall score = 0.7489082969432315\n",
      "\n",
      "F1 Scores\n",
      "macro F1 score = 0.5327846831403961\n",
      "micro F1 score = 0.7489082969432315\n",
      "weighted F1 score = 0.7320941141075613\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics for NB for the Feature Space with K-best features k = 1000\n",
    "\n",
    "true_label_list = y_test_rev_series.to_list()\n",
    "predict_label_list_k1 = list(predictions_k1)\n",
    "\n",
    "acc_score = accuracy_score(true_label_list, predict_label_list_k1)\n",
    "\n",
    "prec_score_macro = precision_score(true_label_list, predict_label_list_k1, average='macro')\n",
    "prec_score_micro = precision_score(true_label_list, predict_label_list_k1, average='micro')\n",
    "prec_score_weighted = precision_score(true_label_list, predict_label_list_k1, average='weighted')\n",
    "\n",
    "rec_score_macro = recall_score(true_label_list, predict_label_list_k1, average='macro')\n",
    "rec_score_micro = recall_score(true_label_list, predict_label_list_k1, average='micro')\n",
    "rec_score_weighted = recall_score(true_label_list, predict_label_list_k1, average='weighted')\n",
    "\n",
    "f1_score_macro = f1_score(true_label_list, predict_label_list_k1, average='macro')\n",
    "f1_score_micro = f1_score(true_label_list, predict_label_list_k1, average='micro')\n",
    "f1_score_weighted = f1_score(true_label_list, predict_label_list_k1, average='weighted')\n",
    "\n",
    "\n",
    "print('Evaluation Reports - NB wfor the Feature Space with K-best features k = 1000')\n",
    "print()\n",
    "print(f'Accuracy Score: {acc_score}')\n",
    "print()\n",
    "print('Precision Scores')\n",
    "print(f'macro precision score = {prec_score_macro}')\n",
    "print(f'micro precision score = {prec_score_micro}')\n",
    "print(f'weighted precision score = {prec_score_weighted}')\n",
    "print()\n",
    "print('Recall Scores')\n",
    "print(f'macro recall score = {rec_score_macro}')\n",
    "print(f'micro recall score = {rec_score_micro}')\n",
    "print(f'weighted recall score = {rec_score_weighted}')\n",
    "print()\n",
    "print('F1 Scores')\n",
    "print(f'macro F1 score = {f1_score_macro}')\n",
    "print(f'micro F1 score = {f1_score_micro}')\n",
    "print(f'weighted F1 score = {f1_score_weighted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature space before filtering:  (1829, 5551)\n",
      "Train feature space after filtering:  (1829, 2000)\n",
      "Test feature space before filtering:  (458, 5551)\n",
      "Test feature space after filtering:  (458, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Selecting K-best features with k = 2000\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "selector = SelectKBest(chi2, k=2000)\n",
    "X_train_features_filtered_kbest2 = selector.fit_transform(x_train_cv, y_train_rev_series)\n",
    "print (\"Train feature space before filtering: \", x_train_cv.shape)\n",
    "print (\"Train feature space after filtering: \", X_train_features_filtered_kbest2.shape)\n",
    "\n",
    "X_test_features_filtered_kbest2 = selector.transform(x_test_cv)\n",
    "print (\"Test feature space before filtering: \", x_test_cv.shape)\n",
    "print (\"Test feature space after filtering: \", X_test_features_filtered_kbest2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'neutral', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'positive',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'neutral', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'neutral', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'neutral',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'negative', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'positive',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'positive', 'neutral', 'positive', 'positive', 'positive',\n",
       "       'positive', 'neutral', 'negative', 'positive', 'positive',\n",
       "       'negative', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'neutral',\n",
       "       'negative', 'negative', 'neutral', 'negative', 'negative',\n",
       "       'negative', 'negative', 'positive', 'positive', 'negative',\n",
       "       'positive', 'positive', 'positive', 'positive', 'negative',\n",
       "       'positive', 'negative', 'positive', 'negative', 'negative',\n",
       "       'positive', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'negative', 'positive', 'positive',\n",
       "       'positive', 'positive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'positive', 'positive', 'negative', 'positive',\n",
       "       'negative', 'negative', 'positive', 'negative', 'positive',\n",
       "       'negative', 'positive', 'negative', 'positive', 'negative',\n",
       "       'negative', 'positive', 'neutral', 'negative', 'positive',\n",
       "       'positive', 'positive', 'positive'], dtype='<U8')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training an NB Model for the Feature Space with K-best features k = 2000\n",
    "\n",
    "# Define true labels from train set\n",
    "\n",
    "x_train_cv_k2 = X_train_features_filtered_kbest2\n",
    "y_train_rev_series = full_train_df[\"three rating\"]\n",
    "x_test_cv_k2 = X_test_features_filtered_kbest2\n",
    "y_test_rev_series = full_test_df[\"three rating\"]\n",
    "\n",
    "# Build model on the training data\n",
    "\n",
    "mnb_model = MultinomialNB()\n",
    "mnb_model.fit(x_train_cv_k2, y_train_rev_series)\n",
    "\n",
    "# Predict the labels for the test data\n",
    "\n",
    "predictions_k2 = mnb_model.predict(x_test_cv_k2)\n",
    "predictions_k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Reports - NB for the Feature Space with K-best features k = 2000\n",
      "\n",
      "Accuracy Score: 0.7379912663755459\n",
      "\n",
      "Precision Scores\n",
      "macro precision score = 0.5207628839081421\n",
      "micro precision score = 0.7379912663755459\n",
      "weighted precision score = 0.7152427888953939\n",
      "\n",
      "Recall Scores\n",
      "macro recall score = 0.48728002849833213\n",
      "micro recall score = 0.7379912663755459\n",
      "weighted recall score = 0.7379912663755459\n",
      "\n",
      "F1 Scores\n",
      "macro F1 score = 0.49498356240232805\n",
      "micro F1 score = 0.7379912663755459\n",
      "weighted F1 score = 0.7179665704150677\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Metrics for NB for the Feature Space with K-best features k = 2000\n",
    "\n",
    "true_label_list = y_test_rev_series.to_list()\n",
    "predict_label_list_k2 = list(predictions_k2)\n",
    "\n",
    "acc_score = accuracy_score(true_label_list, predict_label_list_k2)\n",
    "\n",
    "prec_score_macro = precision_score(true_label_list, predict_label_list_k2, average='macro')\n",
    "prec_score_micro = precision_score(true_label_list, predict_label_list_k2, average='micro')\n",
    "prec_score_weighted = precision_score(true_label_list, predict_label_list_k2, average='weighted')\n",
    "\n",
    "rec_score_macro = recall_score(true_label_list, predict_label_list_k2, average='macro')\n",
    "rec_score_micro = recall_score(true_label_list, predict_label_list_k2, average='micro')\n",
    "rec_score_weighted = recall_score(true_label_list, predict_label_list_k2, average='weighted')\n",
    "\n",
    "f1_score_macro = f1_score(true_label_list, predict_label_list_k2, average='macro')\n",
    "f1_score_micro = f1_score(true_label_list, predict_label_list_k2, average='micro')\n",
    "f1_score_weighted = f1_score(true_label_list, predict_label_list_k2, average='weighted')\n",
    "\n",
    "\n",
    "print('Evaluation Reports - NB for the Feature Space with K-best features k = 2000')\n",
    "print()\n",
    "print(f'Accuracy Score: {acc_score}')\n",
    "print()\n",
    "print('Precision Scores')\n",
    "print(f'macro precision score = {prec_score_macro}')\n",
    "print(f'micro precision score = {prec_score_micro}')\n",
    "print(f'weighted precision score = {prec_score_weighted}')\n",
    "print()\n",
    "print('Recall Scores')\n",
    "print(f'macro recall score = {rec_score_macro}')\n",
    "print(f'micro recall score = {rec_score_micro}')\n",
    "print(f'weighted recall score = {rec_score_weighted}')\n",
    "print()\n",
    "print('F1 Scores')\n",
    "print(f'macro F1 score = {f1_score_macro}')\n",
    "print(f'micro F1 score = {f1_score_micro}')\n",
    "print(f'weighted F1 score = {f1_score_weighted}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Lexicon-based feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
