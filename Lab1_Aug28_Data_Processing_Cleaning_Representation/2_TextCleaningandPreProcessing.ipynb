{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries here that you need for different processing steps\n",
    "import nltk\n",
    "import csv\n",
    "import spacy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  41159\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>ScreenName</th>\n",
       "      <th>Location</th>\n",
       "      <th>TweetAt</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>48751</td>\n",
       "      <td>London</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>48752</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>48753</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>48754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>48755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16-03-2020</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41154</th>\n",
       "      <td>44951</td>\n",
       "      <td>89903</td>\n",
       "      <td>Wellington City, New Zealand</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Airline pilots offering to stock supermarket s...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41155</th>\n",
       "      <td>44952</td>\n",
       "      <td>89904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Response to complaint not provided citing COVI...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41156</th>\n",
       "      <td>44953</td>\n",
       "      <td>89905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41157</th>\n",
       "      <td>44954</td>\n",
       "      <td>89906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41158</th>\n",
       "      <td>44955</td>\n",
       "      <td>89907</td>\n",
       "      <td>i love you so much || he/him</td>\n",
       "      <td>14-04-2020</td>\n",
       "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41159 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserName ScreenName                      Location     TweetAt  \\\n",
       "0         3799      48751                        London  16-03-2020   \n",
       "1         3800      48752                            UK  16-03-2020   \n",
       "2         3801      48753                     Vagabonds  16-03-2020   \n",
       "3         3802      48754                           NaN  16-03-2020   \n",
       "4         3803      48755                           NaN  16-03-2020   \n",
       "...        ...        ...                           ...         ...   \n",
       "41154    44951      89903  Wellington City, New Zealand  14-04-2020   \n",
       "41155    44952      89904                           NaN  14-04-2020   \n",
       "41156    44953      89905                           NaN  14-04-2020   \n",
       "41157    44954      89906                           NaN  14-04-2020   \n",
       "41158    44955      89907  i love you so much || he/him  14-04-2020   \n",
       "\n",
       "                                           OriginalTweet           Sentiment  \n",
       "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1      advice Talk to your neighbours family to excha...            Positive  \n",
       "2      Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3      My food stock is not the only one which is emp...            Positive  \n",
       "4      Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "...                                                  ...                 ...  \n",
       "41154  Airline pilots offering to stock supermarket s...             Neutral  \n",
       "41155  Response to complaint not provided citing COVI...  Extremely Negative  \n",
       "41156  You know itÂs getting tough when @KameronWild...            Positive  \n",
       "41157  Is it wrong that the smell of hand sanitizer i...             Neutral  \n",
       "41158  @TartiiCat Well new/used Rift S are going for ...            Negative  \n",
       "\n",
       "[41159 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read the csv file into a dataframe\n",
    "\n",
    "data_file = \"./Dataset/covid.csv\"\n",
    "\n",
    "data_df = pd.read_csv(data_file)\n",
    "print (\"Training set: \", len(data_df))\n",
    "\n",
    "display(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Cleaning and Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting Sentiment Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive              11422\n",
      "Negative               9917\n",
      "Neutral                7711\n",
      "Extremely Positive     6624\n",
      "Extremely Negative     5481\n",
      "Name: Sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Run the cell to see the distribution of the sentiment label in the dataset\n",
    "\n",
    "print(data_df.Sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Columns\n",
    "Identify the column that you think is less relevant for text mining or other NLP tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41159, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>Location</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>London</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>UK</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3804</td>\n",
       "      <td>ÃT: 36.319708,-82.363649</td>\n",
       "      <td>As news of the regionÂs first confirmed COVID...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3805</td>\n",
       "      <td>35.926541,-78.753267</td>\n",
       "      <td>Cashier at grocery store was sharing his insig...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3806</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Was at the supermarket today. Didn't buy toile...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3807</td>\n",
       "      <td>Atlanta, GA USA</td>\n",
       "      <td>Due to COVID-19 our retail store and classroom...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3808</td>\n",
       "      <td>BHAVNAGAR,GUJRAT</td>\n",
       "      <td>For corona prevention,we should stop to buy th...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserName                   Location  \\\n",
       "0     3799                     London   \n",
       "1     3800                         UK   \n",
       "2     3801                  Vagabonds   \n",
       "3     3802                        NaN   \n",
       "4     3803                        NaN   \n",
       "5     3804  ÃT: 36.319708,-82.363649   \n",
       "6     3805       35.926541,-78.753267   \n",
       "7     3806                    Austria   \n",
       "8     3807            Atlanta, GA USA   \n",
       "9     3808           BHAVNAGAR,GUJRAT   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  \n",
       "5  As news of the regionÂs first confirmed COVID...            Positive  \n",
       "6  Cashier at grocery store was sharing his insig...            Positive  \n",
       "7  Was at the supermarket today. Didn't buy toile...             Neutral  \n",
       "8  Due to COVID-19 our retail store and classroom...            Positive  \n",
       "9  For corona prevention,we should stop to buy th...            Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.drop(['ScreenName','TweetAt'],axis=1,inplace=True)\n",
    "print(data_df.shape)\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling NULL values\n",
    "Handle null values in a column by specifying the alternate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e62064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Neutral\n",
       "1                  Positive\n",
       "2                  Positive\n",
       "3                  Positive\n",
       "4        Extremely Negative\n",
       "                ...        \n",
       "41154               Neutral\n",
       "41155    Extremely Negative\n",
       "41156              Positive\n",
       "41157               Neutral\n",
       "41158              Negative\n",
       "Name: Sentiment, Length: 41159, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_col_df = data_df['Sentiment'].fillna(\"NA\")\n",
    "filled_col_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>Location</th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3799</td>\n",
       "      <td>London</td>\n",
       "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3800</td>\n",
       "      <td>UK</td>\n",
       "      <td>advice Talk to your neighbours family to excha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3801</td>\n",
       "      <td>Vagabonds</td>\n",
       "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3802</td>\n",
       "      <td>NA</td>\n",
       "      <td>My food stock is not the only one which is emp...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3803</td>\n",
       "      <td>NA</td>\n",
       "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserName   Location                                      OriginalTweet  \\\n",
       "0     3799     London  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
       "1     3800         UK  advice Talk to your neighbours family to excha...   \n",
       "2     3801  Vagabonds  Coronavirus Australia: Woolworths to give elde...   \n",
       "3     3802         NA  My food stock is not the only one which is emp...   \n",
       "4     3803         NA  Me, ready to go at supermarket during the #COV...   \n",
       "\n",
       "            Sentiment  \n",
       "0             Neutral  \n",
       "1            Positive  \n",
       "2            Positive  \n",
       "3            Positive  \n",
       "4  Extremely Negative  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run this cell to fill all null values in all columns of the dataframe with the desired value. \n",
    "# Trying doing it for a single column yourself.\n",
    "\n",
    "data_df = data_df.fillna(\"NA\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Exceptions\n",
    "Use try-except-pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate the statements within a try-except block where you suspect there might be errors.\n",
    "# In the except block, handle the exception according to the requirement.\n",
    "\n",
    "try:\n",
    "    data_df=data_df.fillna(\"NA\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercase conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing lower case conversion of Tweet for an instance\n",
    "\n",
    "print(data_df.OriginalTweet.tolist()[100])\n",
    "print(\"\\n\")\n",
    "print(data_df.OriginalTweet.tolist()[100].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Special Characters or links\n",
    "\n",
    "This should be an interesting step. You can remove special characters or links or anything that does not have value for the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing removal of special chars from the Tweet for an instance\n",
    "\n",
    "import re\n",
    "\n",
    "print(data_df.OriginalTweet.tolist()[100])\n",
    "print(\"\\n\")\n",
    "print(re.sub('[^A-Za-z0-9]+', ' ', data_df.OriginalTweet.tolist()[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT PRE-PROCESSING\n",
    "\n",
    "The following are the techniques to tranform the data into a cleaner data. Try out the what all techniques you would apply to your textual data to get the best quality dataset for a model.\n",
    "You can use either/all/addition to these steps mentioned below in any order that you find appropriate.\n",
    "\n",
    "- Tokenization\n",
    "- Sentence Segmentation\n",
    "\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- PartOfSpeech Tagging\n",
    "- Others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to see an example of text pre-processing including a few of these techniques. \n",
    "# This image is a hint to the pre-processing steps but may or may not be the best. \n",
    "# It shows how the input text changes with each processing step\n",
    "# Find out different Tokenizers, Stemmers, Lemmatizers, etc and try to use the best one for your task! \n",
    "\n",
    "from PIL import Image\n",
    "pil_im = Image.open('./Dataset/Text_preprocessing_example.png')\n",
    "display(pil_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization using nltk library\n",
    " Links to a few word and sentence tokenizers- https://www.nltk.org/howto/tokenize.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing tokenization of the Tweets into words for an instance\n",
    "\n",
    "from nltk.tokenize import word_tokenize  \n",
    "\n",
    "print(data_df.OriginalTweet.tolist()[100])\n",
    "print(\"\\n\")\n",
    "print(word_tokenize(data_df.OriginalTweet.tolist()[100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "Links to a few nltk Stemmers- https://www.nltk.org/howto/stem.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example showing stemming of words\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "\n",
    "print(data_df.OriginalTweet.tolist()[51])\n",
    "print(\"\\n\")\n",
    "\n",
    "tweet = data_df.OriginalTweet.tolist()[51].split()\n",
    "\n",
    "for word in tweet:\n",
    "    print(word,\" \",ps.stem(word) ,\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
